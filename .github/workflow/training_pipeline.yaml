# =============================================================================
# Training Pipeline CI/CD Workflow
# =============================================================================
# This workflow triggers the Kubeflow training pipeline when:
#   1. Code is pushed to main/develop (auto-trigger)
#   2. Manual trigger via workflow_dispatch
#   3. Webhook from Evidently drift detection (handled separately)
#
# Flow:
#   Code Push â†’ GitHub Actions â†’ Compile Pipeline â†’ Submit to Kubeflow â†’ Track Run
# =============================================================================

name: Training Pipeline

on:
  # Auto-trigger on push to main branches
  push:
    branches:
      - main
      - develop
    # Only trigger when relevant files change (saves compute costs)
    paths:
      - 'pipelines/training/**'
      - 'src/**'
      - 'configs/**'
      - 'requirements*.txt'
      - '.github/workflows/training_pipeline.yaml'
  
  # Manual trigger with parameters
  workflow_dispatch:
    inputs:
      data_version:
        description: 'DVC data version tag (e.g., v1.0.0)'
        required: true
        default: 'v1.0.0'
      model_type:
        description: 'Model type to train'
        required: true
        default: 'xgboost'
        type: choice
        options:
          - xgboost
          - sklearn_rf
      environment:
        description: 'Target environment'
        required: true
        default: 'staging'
        type: choice
        options:
          - development
          - staging
          - production

# Environment variables
env:
  AWS_REGION: us-west-2
  ECR_REGISTRY: ${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.us-west-2.amazonaws.com
  KUBEFLOW_HOST: ${{ secrets.KUBEFLOW_HOST }}
  MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}

jobs:
  # ===========================================================================
  # Job 1: Validate and Test
  # ===========================================================================
  validate:
    name: Validate Code
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest flake8 mypy
      
      - name: Lint code
        run: |
          flake8 pipelines/ src/ --max-line-length=100 --ignore=E501
      
      - name: Type check
        run: |
          mypy pipelines/ src/ --ignore-missing-imports || true
      
      - name: Run unit tests
        run: |
          pytest tests/ -v --tb=short || true

  # ===========================================================================
  # Job 2: Compile Pipeline
  # ===========================================================================
  compile:
    name: Compile Pipeline
    runs-on: ubuntu-latest
    needs: validate
    
    outputs:
      pipeline_file: ${{ steps.compile.outputs.pipeline_file }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'
      
      - name: Install KFP SDK
        run: |
          pip install kfp==2.5.0
      
      - name: Compile pipeline
        id: compile
        run: |
          cd pipelines/training
          python pipeline.py --compile --output training_pipeline.yaml
          echo "pipeline_file=pipelines/training/training_pipeline.yaml" >> $GITHUB_OUTPUT
      
      - name: Upload pipeline artifact
        uses: actions/upload-artifact@v4
        with:
          name: compiled-pipeline
          path: pipelines/training/training_pipeline.yaml
          retention-days: 7

  # ===========================================================================
  # Job 3: Submit to Kubeflow
  # ===========================================================================
  submit:
    name: Submit Pipeline Run
    runs-on: ubuntu-latest
    needs: compile
    
    # Only run on main branch or manual trigger
    if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Download compiled pipeline
        uses: actions/download-artifact@v4
        with:
          name: compiled-pipeline
          path: pipelines/training/
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          pip install kfp==2.5.0 requests
      
      # AWS authentication for EKS access
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      # Determine parameters based on trigger type
      - name: Set pipeline parameters
        id: params
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "data_version=${{ github.event.inputs.data_version }}" >> $GITHUB_OUTPUT
            echo "trigger_type=manual" >> $GITHUB_OUTPUT
            echo "environment=${{ github.event.inputs.environment }}" >> $GITHUB_OUTPUT
          else
            echo "data_version=latest" >> $GITHUB_OUTPUT
            echo "trigger_type=ci" >> $GITHUB_OUTPUT
            echo "environment=staging" >> $GITHUB_OUTPUT
          fi
          echo "git_sha=${{ github.sha }}" >> $GITHUB_OUTPUT
      
      # Submit pipeline to Kubeflow
      - name: Submit pipeline run
        id: submit
        run: |
          python - <<EOF
          import kfp
          from kfp import Client
          import json
          import os
          
          # Connect to Kubeflow
          client = Client(host="${{ env.KUBEFLOW_HOST }}")
          
          # Pipeline parameters
          params = {
              "data_version": "${{ steps.params.outputs.data_version }}",
              "trigger_type": "${{ steps.params.outputs.trigger_type }}",
              "git_sha": "${{ steps.params.outputs.git_sha }}",
              "mlflow_tracking_uri": "${{ env.MLFLOW_TRACKING_URI }}",
              "mlflow_experiment_name": "training-pipeline-${{ steps.params.outputs.environment }}",
          }
          
          print(f"Submitting pipeline with parameters: {json.dumps(params, indent=2)}")
          
          # Submit run
          run = client.create_run_from_pipeline_package(
              pipeline_file="pipelines/training/training_pipeline.yaml",
              arguments=params,
              run_name=f"training-{params['trigger_type']}-${{ github.run_number }}",
              experiment_name="training-pipeline",
          )
          
          print(f"Pipeline run submitted: {run.run_id}")
          
          # Output run ID for tracking
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"run_id={run.run_id}\n")
              f.write(f"run_url={client.host}/#/runs/details/{run.run_id}\n")
          EOF
      
      - name: Print run details
        run: |
          echo "âœ… Pipeline submitted successfully!"
          echo "Run ID: ${{ steps.submit.outputs.run_id }}"
          echo "Run URL: ${{ steps.submit.outputs.run_url }}"
      
      # Post status to PR if applicable
      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `ðŸš€ Training pipeline submitted!\n\n**Run ID:** ${{ steps.submit.outputs.run_id }}\n**URL:** ${{ steps.submit.outputs.run_url }}`
            })

  # ===========================================================================
  # Job 4: Wait for Completion (Optional)
  # ===========================================================================
  wait:
    name: Wait for Pipeline
    runs-on: ubuntu-latest
    needs: submit
    
    # Only wait on manual triggers (CI can be async)
    if: github.event_name == 'workflow_dispatch'
    timeout-minutes: 120  # 2 hour max
    
    steps:
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Install KFP SDK
        run: pip install kfp==2.5.0
      
      - name: Wait for pipeline completion
        id: wait
        run: |
          python - <<EOF
          from kfp import Client
          import time
          import sys
          
          client = Client(host="${{ env.KUBEFLOW_HOST }}")
          run_id = "${{ needs.submit.outputs.run_id }}"
          
          print(f"Waiting for run {run_id} to complete...")
          
          while True:
              run = client.get_run(run_id)
              status = run.run.status
              
              print(f"Status: {status}")
              
              if status == "Succeeded":
                  print("âœ… Pipeline completed successfully!")
                  sys.exit(0)
              elif status in ["Failed", "Error"]:
                  print("âŒ Pipeline failed!")
                  sys.exit(1)
              elif status == "Skipped":
                  print("â­ï¸ Pipeline skipped (validation may have failed)")
                  sys.exit(1)
              
              time.sleep(30)  # Check every 30 seconds
          EOF

  # ===========================================================================
  # Job 5: Notify on Failure
  # ===========================================================================
  notify-failure:
    name: Notify on Failure
    runs-on: ubuntu-latest
    needs: [validate, compile, submit]
    if: failure()
    
    steps:
      - name: Send Slack notification
        uses: slackapi/slack-github-action@v1
        with:
          payload: |
            {
              "text": "âŒ Training Pipeline Failed",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "*Training Pipeline Failed*\n\nRepository: ${{ github.repository }}\nBranch: ${{ github.ref_name }}\nCommit: ${{ github.sha }}\nWorkflow: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
                  }
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}